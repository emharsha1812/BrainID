{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c086dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries and frameworks\n",
    "import tensorflow as tf\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn.preprocessing\n",
    "from scipy.signal import butter,lfilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "54c52fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a butterworth filtter bandpass\n",
    "def butter_bandpass(lowcut,highcut,fs,order=5):\n",
    "    #Nyquist rate fs=2*fm\n",
    "    #fm=0.5*fs\n",
    "    nyq=0.5*fs\n",
    "    lowcut=lowcut/nyq\n",
    "    highcut=highcut/nyq\n",
    "    #b,a=numerator and denominator values of the IIR Filter\n",
    "    b,a=butter(order,[lowcut,highcut],btype='band')\n",
    "    return b,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5c3875a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining one hot encoding\n",
    "#This function is used to transfer one column label to one hot label\n",
    "def one_hot(y_):\n",
    "    #Function to encode output labels from number indexes\n",
    "    #e.g [[5],[3],[0]] --> [[0,0,0,0,0,1],[0,0,0,1,0,0],[0,0,0,0,0,0]]\n",
    "#     y_=y_.reshape((len(y_)))\n",
    "    y_=np.array(y_)\n",
    "    y_=y_.reshape(len(y_))\n",
    "    n_values=np.max(y_)+1\n",
    "    return np.eye(int(n_values))[np.array(y_,dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "60d06479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Checking\n",
    "a1=[[5],[3],[2]]\n",
    "a2=one_hot(a1)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f92dc082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data,lowcut,highcut,fs,order=5):\n",
    "    b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "    y=lfilter(b,a,data)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e0cd8",
   "metadata": {},
   "source": [
    "Defining some variables used to load and process the EEG Data\n",
    "1. **len_sample** = Length of each sample ( in seconds )\n",
    "2. **full**= total number of samples per subject \n",
    "3. **n_fea**=number of features ( EEG Channels )\n",
    "4. **label0-label7** = Defines the labels for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "19e9bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [7.]\n",
      " [7.]\n",
      " [7.]]\n"
     ]
    }
   ],
   "source": [
    "len_sample=1\n",
    "full=7000\n",
    "len_a=int(full/len_sample)\n",
    "label0=np.zeros(len_a)\n",
    "label1=np.ones(len_a)\n",
    "label2=np.ones(len_a)*2\n",
    "label3=np.ones(len_a)*3\n",
    "label4=np.ones(len_a)*4\n",
    "label5=np.ones(len_a)*5\n",
    "label6=np.ones(len_a)*6\n",
    "label7=np.ones(len_a)*7\n",
    "label=np.hstack((label0,label1,label2,label3,label4,label5,label6,label7))\n",
    "label=label.T\n",
    "label.shape=(len(label),1)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "42c71ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start1=time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d4fb6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=sc.io.loadmat(\"EID-S.mat\")\n",
    "all=feature['eeg_close_8sub_1file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a5784f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fea=14\n",
    "all=all[0:full*8,0:n_fea]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edde3f",
   "metadata": {},
   "source": [
    "### Next steps - Performing a filtering operation on a EEG Dataset to extract the delta wave pattern using a Butterworth filter\n",
    "\n",
    "1. **start2**= measures the starting time using `time.process_time()` function and stores it in a variable\n",
    "2. Initialize an empty list **data_f1** to store the filtered EEG data\n",
    "3. Loop over the columns of the `all` array using `range(all.shape[1])`\n",
    "4. For each column, applies a bandpass filter using the butter_bandpass_filter function with the specified lowcut, highcut and sampling frequency values. The filtered data is then stored in the `data_f1 list`.\n",
    "5. Convert the `data_f1` list to a numpy array and then transpose it\n",
    "6. Replace the original `all` array with the filtered data array `data_f1`\n",
    "7. Measure the ending time using the `time.process_time()` function and store it in a variable `time3`\n",
    "8. Print the shape of the filtered data array and the elapsed timem for the filtering operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "20c5fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timing the process\n",
    "start=time.process_time()\n",
    "\n",
    "#Empty list\n",
    "data_f1=[]\n",
    "for i in range(all.shape[1]):\n",
    "    x=all[:,i]\n",
    "    fs=128.0\n",
    "    lowcut=0.5\n",
    "    highcut=4.0\n",
    "    y=butter_bandpass_filter(x,lowcut,highcut,fs,order=3)\n",
    "    data_f1.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cf671395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_f1.shape (56000, 14)\n"
     ]
    }
   ],
   "source": [
    "data_f1=np.array(data_f1)\n",
    "data_f1=data_f1.T\n",
    "print('data_f1.shape',data_f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c85a4334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD time 0.0\n",
      "(56000, 15)\n"
     ]
    }
   ],
   "source": [
    "all=data_f1\n",
    "end=time.process_time()\n",
    "print('PD time',start-end)\n",
    "all=np.hstack((all,label))\n",
    "print(all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "155fa092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [7.]\n",
      " [7.]\n",
      " [7.]]\n"
     ]
    }
   ],
   "source": [
    "#all=combine data\n",
    "data_size=all.shape[0]\n",
    "\n",
    "feature_all=all[:,0:n_fea]\n",
    "print(all[:,n_fea:n_fea+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ecdedd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_all=feature_all-4200 #minus Direct Current\n",
    "#z-score scaling\n",
    "feature_all=sklearn.preprocessing.scale(feature_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26ea0e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 15)\n"
     ]
    }
   ],
   "source": [
    "label_all=all[:,n_fea:n_fea+1]\n",
    "all=np.hstack((feature_all,label_all))\n",
    "print(all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0b91dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the first subject as testing subject\n",
    "np.random.shuffle(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "20c98111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=all[0:int(data_size*0.875)] #Training data is 87.5% of original\n",
    "test_data=all[int(data_size*0.875):data_size]\n",
    "\n",
    "no_fea=n_fea\n",
    "n_steps=len_sample\n",
    "\n",
    "feature_training=train_data[:,0:no_fea]\n",
    "feature_training=feature_training.reshape([train_data.shape[0],n_steps,no_fea])\n",
    "\n",
    "feature_testing=test_data[:,0:no_fea]\n",
    "feature_training = feature_training.reshape([train_data.shape[0], n_steps, no_fea])\n",
    "\n",
    "\n",
    "feature_testing = test_data[:,0:no_fea]\n",
    "\n",
    "feature_testing = feature_testing.reshape([test_data.shape[0], n_steps, no_fea])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "acca35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 7. 3. 6.]\n"
     ]
    }
   ],
   "source": [
    "label_training=train_data[:,no_fea]\n",
    "label_training=one_hot(label_training)\n",
    "label_testing=test_data[:,no_fea]\n",
    "print(label_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c9428c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8c0c9",
   "metadata": {},
   "source": [
    "### Batch Splitting\n",
    "**Splitting the input data into batches for training in order to process it more efficiently**\n",
    "\n",
    "***Steps Involved***\n",
    "1. It calculates the batch size by multiplying the total data size by 0.125 (12.5%).\n",
    "2. It creates an empty list called train_fea.\n",
    "3. It sets the number of groups to 7.\n",
    "4. It loops through each group and selects the corresponding slice of the feature_training array to add to the train_fea list. Each slice is determined by multiplying the batch size by the group index and adding 0 to the start and end indices for the first group, adding one batch size to both the start and end indices for the second group, and so on. The result is that train_fea is a list of 7 arrays, each with batch_size rows and some number of columns.\n",
    "5. It prints the shape of the first element of train_fea (which should be (batch_size, num_features)) and the elements of rows 235 and 236 of the first element of train_fea.\n",
    "6. It creates an empty list called train_label.\n",
    "7. It loops through each group and selects the corresponding slice of the label_training array to add to the train_label list. The slices are determined in the same way as for train_fea. The result is that train_label is a list of 7 arrays, each with batch_size rows and some number of columns.\n",
    "8. It prints the shape of the first element of train_label (which should be (batch_size, num_classes)). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1c57264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 1, 14)\n",
      "[[[ 0.042783    0.1377656  -0.01978495  0.00890953 -0.0072165\n",
      "    0.06600291 -0.03770078 -0.01082981 -0.07334202  0.03269157\n",
      "    0.06984906  0.00142352  0.04783427  0.01854654]]\n",
      "\n",
      " [[-0.17298104 -0.07393439 -0.03212914  0.19396801 -0.09174386\n",
      "    0.16028462  0.0908069  -0.0637945  -0.1560574  -0.14098168\n",
      "    0.00060067 -0.02152958 -0.13572034 -0.16545925]]]\n",
      "(7000, 8)\n"
     ]
    }
   ],
   "source": [
    "a=feature_training\n",
    "b=feature_testing\n",
    "nodes=30\n",
    "lameda=0.001\n",
    "lr=0.001\n",
    "\n",
    "batch_size=int(data_size*0.125)\n",
    "\n",
    "n_group=7\n",
    "\n",
    "def range_calculator(listname,listdest):\n",
    "    for i in range(n_group):\n",
    "        f=listname[(0+batch_size*i):(batch_size+batch_size*i)]\n",
    "        listdest.append(f)\n",
    "\n",
    "train_fea=[]\n",
    "train_label=[]\n",
    "\n",
    "range_calculator(a,train_fea)\n",
    "range_calculator(label_training,train_label)\n",
    "\n",
    "print(train_fea[0].shape)\n",
    "print(train_fea[0][235:237])\n",
    "\n",
    "print(train_label[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619e202",
   "metadata": {},
   "source": [
    "### Defining an RNN Cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1d167978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "n_inputs=no_fea\n",
    "n_hidden1_units=nodes\n",
    "n_hidden2_units=nodes\n",
    "n_hidden3_units=nodes\n",
    "n_hidden4_units=nodes\n",
    "n_classes=8\n",
    "\n",
    "#tf graph input \n",
    "x=tf.keras.layers.Input(shape=(None,n_inputs),name=\"x\",dtype='float32')\n",
    "y=tf.keras.layers.Input(shape=(n_classes),dtype='float32',name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "93586fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining weights\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random.normal([n_inputs, n_hidden1_units]), trainable=True),\n",
    "    'a': tf.Variable(tf.random.normal([n_hidden1_units, n_hidden1_units]), trainable=True),\n",
    "    'hidd2': tf.Variable(tf.random.normal([n_hidden1_units, n_hidden2_units])),\n",
    "    'hidd3': tf.Variable(tf.random.normal([n_hidden2_units, n_hidden3_units])),\n",
    "    'hidd4': tf.Variable(tf.random.normal([n_hidden3_units, n_hidden4_units])),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden4_units, n_classes]), trainable=True),\n",
    "    'att': tf.Variable(tf.random.normal([n_inputs, n_hidden4_units]), trainable=True),\n",
    "    'att2': tf.Variable(tf.random.normal([1, batch_size]), trainable=True),\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden1_units])),\n",
    "    'hidd2': tf.Variable(tf.constant(0.1, shape=[n_hidden2_units])),\n",
    "    'hidd3': tf.Variable(tf.constant(0.1, shape=[n_hidden3_units])),\n",
    "    'hidd4': tf.Variable(tf.constant(0.1, shape=[n_hidden4_units])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes]), trainable=True),\n",
    "    'att': tf.Variable(tf.constant(0.1, shape=[n_hidden4_units])),\n",
    "    'att2': tf.Variable(tf.constant(0.1, shape=[n_hidden4_units])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3b99384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(14, 30) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(30,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(30, 30) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(30,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(30, 30) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(30,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[170], line 35\u001b[0m\n\u001b[0;32m     30\u001b[0m     results\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mmatmul(outputs_att,weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m+\u001b[39mbiases[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results,outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 35\u001b[0m pred,Feature,_\u001b[38;5;241m=\u001b[39m\u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[170], line 22\u001b[0m, in \u001b[0;36mRNN\u001b[1;34m(X, weights, biases)\u001b[0m\n\u001b[0;32m     19\u001b[0m lstm_cell_1\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTMCell(n_hidden3_units,unit_forget_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m init_state\u001b[38;5;241m=\u001b[39mlstm_cell_1\u001b[38;5;241m.\u001b[39mget_initial_state(batch_size\u001b[38;5;241m=\u001b[39mbatch_size,dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 22\u001b[0m outputs,final_state\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRNN(lstm_cell_1,return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,return_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(X_in,initial_state\u001b[38;5;241m=\u001b[39minit_state)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#outputs\u001b[39;00m\n\u001b[0;32m     25\u001b[0m outputs\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39munstack(tf\u001b[38;5;241m.\u001b[39mtranspose(outputs,[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m])) \u001b[38;5;66;03m#states is the last output\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def RNN(X,weights,biases):\n",
    "    #hidden layer for input to cell\n",
    "    ##############################\n",
    "    \n",
    "    X=tf.reshape(X,[-1,n_inputs])\n",
    "    \n",
    "    #hidden layer\n",
    "    X_hidd1=tf.sigmoid(tf.matmul(X,weights['in'])+biases['in'])\n",
    "    X_hidd2=tf.matmul(X_hidd1,weights['hidd2'])+biases['hidd2']\n",
    "    X_hidd3=tf.matmul(X_hidd2,weights['hidd3'])+biases['hidd3']\n",
    "    \n",
    "    X_in=tf.reshape(X_hidd3,[-1,n_steps,n_hidden4_units])\n",
    "    \n",
    "    \n",
    "    #cell\n",
    "    #####################################\n",
    "    \n",
    "    #basic LSTM Cell\n",
    "    lstm_cell_1=tf.keras.layers.LSTMCell(n_hidden3_units,unit_forget_bias=True)\n",
    "    init_state=lstm_cell_1.get_initial_state(batch_size=batch_size,dtype=tf.float32)\n",
    "    \n",
    "    outputs,final_state=tf.keras.layers.RNN(lstm_cell_1,return_sequences=True,return_state=True)(X_in,initial_state=init_state)\n",
    "    \n",
    "    #outputs\n",
    "    outputs=tf.unstack(tf.transpose(outputs,[1,0,2])) #states is the last output\n",
    "    \n",
    "    #attention based model\n",
    "    X_att2=final_state[0] #weights\n",
    "    outputs_att=tf.multiply(outputs[-1],X_att2)\n",
    "    results=tf.matmul(outputs_att,weights['out'])+biases['out']\n",
    "    \n",
    "    return results,outputs[-1]\n",
    "\n",
    "\n",
    "pred,Feature,_=RNN(x,weights,biases)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamena=lameda\n",
    "#Computing l2 loss\n",
    "l2=lamena*sum(tf.nn.l2_loss(tf_var) for tf_var in tf.compat.v1.trainable_variables())\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))+l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9e405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
